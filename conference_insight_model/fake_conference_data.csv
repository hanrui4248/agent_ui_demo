Title,Session Type,Date,Description,Topic,Expert Insight,Expert Insight merged,Speaker,Composer
AI Ethics in Healthcare,Workshop,2025-04-12,Interactive workshop exploring ethical considerations when implementing AI in healthcare settings.,Ethics,"[{""核心观点"": ""提出GREATS（Guided Reading of Exemplar Adaptive Training Selection）方法，旨在在LLMs训练每个迭代过程中在线选择高质量数据。首先定义一系列用于评估数据质量的指标，包括多样性、相关性、一致性和信息量等。利用预训练模型或辅助模型，对每个训练样本进行评分，在每步训练迭代中，动态选择一部分高质量的数据用于当前迭代的训练。根据训练进度和模型需求，动态调整数据选择的阈值，同时引入多样性约束，确保数据选择的灵活性和适应性。"", ""对华为的启示"": ""GREATS通过在线选择高质量数据，显著提升模型的训练效率和性能，减少了不必要的数据处理开销，与现有训练流程无缝集成，易于实施，具备实际应用的可行性，能够快速应用于现有的LLM训练框架中。当前验证只在小Batch Size下进行，规模增大时可能增加内存占用和计算开销，如何Trade off需要进一步探索。""}, {""核心观点"": ""提出种多阶段框架，系统分析和量化训练数据随时间变化对模型的影响，旨在提升模型的适应性、鲁棒性和长期性能。将训练数据按照时间顺序划分为多个阶段，引入梯度贡献、样本重要性评分、熵变化等指标，量化每个阶段数据对模型参数和性能的影响，以捕捉数据在不同时间段对模型训练过程中的具体贡献。构建动态模型，合时间序列分析和因果推断方法，描述和预测训练数据在不同阶段对模型性能影响的迟滞和累积效应。"", ""对华为的启示"": ""在早期和晚期预训练阶段数据对模型性能影响较大，可在这两个阶段加入高质量数据提升训练效果。当前只进行小尺度验证，数据对训练不同阶段模型性能影响的Scaling Law，以及不同阶段对数据质量的需求有待进一步探索。""}]",,"[{""name"": ""Sarah Johnson"", ""position"": ""Chief Ethics Officer"", ""company"": ""HealthAI Solutions""}, {""name"": ""Michael Chen"", ""position"": ""Professor of Bioethics"", ""company"": ""Stanford University""}]","[{""name"": ""陈晓"", ""id"": ""56298981""}, {""name"": ""陈晓"", ""id"": ""52191360""}]"
Deep Learning Advancements,Keynote,2025-04-12,Overview of recent breakthroughs in deep learning architectures and applications.,Research,"[{""核心观点"": ""由于机器人将被人类使用，并且与人类近距离接触，我们希望得到一些保证，即给定相同的输入，产生相似的输出。系统应该是可解释和可解释的，因为它将使我们更接近安全和隐私。如果你想应用你生成的抓地，那么你也需要一个真正的交互和真正的触觉反馈，理解和推理你生成的抓地是否稳定。可能的HRI包括携带重物四处走动，辅导，以及机器人应该如何表现等方面。"", ""对华为的启示"": ""为了讲道理，仅有感知是不够的。触觉反馈也应该包含在EAI项目中（回忆：Tesla Optimus =摄像头+触觉反馈）需要多模态反馈。""}, {""核心观点"": ""这场以学习交互与交互学习为主题的演讲，全面探讨了机器人技术的现状、挑战和未来发展方向。Kragic教授强调将传统的基于规则的方法与现代数据驱动方法相结合的重要性，指出虽然现代系统在语言模型和视觉模型的应用上展现出令人印象深刻的能力，但在灵巧操作、多模态反馈以及处理可变形物体等方面仍面临重大挑战。研究方向应聚焦于表征学习、多模态感知集成、物理模拟器改进等领域。展望未来5-10年，机器人技术有望在仓储等受控环境中得到广泛应用，但在医疗护理等更复杂领域的应用还需更长时间。Kragic教授最后强调，尽管机器人技术已取得显著进展，但在创建能够处理现实世界复杂物理互动的稳健、安全和可靠系统方面，仍需要通过将传统机器人技术与现代人工智能相结合来实现突破。"", ""对华为的启示"": ""3D空间智能与机器人的融合是未来发展的重要方向。机器人在复杂领域的应用还需要更长时间，我司应该意识到这是一个需要长期投入、需要耐心培育的方向，不能期待短期回报，但可能带来颠覆性的机会。""}]",,"[{""name"": ""David Kumar"", ""position"": ""Director of AI Research"", ""company"": ""DeepMind""}, {""name"": ""Elizabeth Tran"", ""position"": ""Chief Scientist"", ""company"": ""NeuralTech Inc""}]","[{""name"": ""孙宇"", ""id"": ""52132969""}, {""name"": ""郑洁"", ""id"": ""45237151""}]"
Responsible AI Development,Panel,2025-04-13,Industry leaders discuss frameworks for responsible AI development and deployment.,Ethics,"[{""核心观点"": ""作者通过新的后视重标记而不使用人类注释，提出了在数据缺失域上的定理证明。在对抗性环境中的自动猜想生成被证明会随着时间的推移生成复杂的猜想，而事后重标记也可以有效地提高定理证明的性能。"", ""对华为的启示"": ""LLM-Reasoning是公司（北极星项目）的重要课题。后知后觉重新标记可能是生成合成数据的潜在有用方法。""}, {""核心观点"": ""MINIMO (Mathematics from Intrinsic Motivation)框架通过三个关键创新实现了AI从数学公理出发自主学习和发现数学知识的能力。该框架利用类型理论和约束解码技术使AI能从公理出发生成有效的数学猜想，使用蒙特卡洛树搜索进行定理证明并通过自我对弈不断提升能力，同时创新性地应用Hindsight Relabeling技术从失败的证明尝试中学习有价值的知识。研究表明该框架在命题逻辑、算术和群论三个数学领域实现了从公理出发的自主学习，证明能力随训练不断提升，能解决越来越复杂的数学问题，并且即使没有人类示例，也能学会证明经典数学教科书中的定理。"", ""对华为的启示"": ""MINIMO框架展示了AI系统可以通过内在动机驱动，实现真正的自主学习，提供了一种新的范式，让AI不依赖人类知识也能探索和发现数学规律，其中的Hindsight Relabeling等技术可以显著提升学习效率，值得在CoT构建方向借鉴应用。""}]",,"[{""name"": ""Robert Williams"", ""position"": ""VP of Ethical AI"", ""company"": ""Microsoft""}, {""name"": ""Linda Zhao"", ""position"": ""Director of Governance"", ""company"": ""Google AI""}]","[{""name"": ""冯雪"", ""id"": ""80921183""}]"
Computer Vision Applications,Technical,2025-04-13,Technical deep dive into latest computer vision algorithms and real-world use cases.,Computer Vision,"[{""核心观点"": ""多模态LLM(MLLM)涉及一个复杂的训练和评估管道，需要考虑许多设计决策。虽然更强大的语言模型可以增强多模态功能，但视觉组件的设计选择往往没有得到充分的探索，并且与视觉表征学习研究脱节。现有的基准可能无法为现实场景提供足够的指导，在这种情况下，视觉基础对于稳健的多模态理解至关重要。作者提出寒武纪-1(Cambrian-1)，它使用各种尺度的LLM主干，并使用空间视觉聚合器在一个策划的数据集（寒武纪-7M/10M）上组合四个视觉模型，以及一个新的以视觉为中心的基准（CV-Bench）来训练一个MLLM集成模型。作者还提出了空间视觉聚合器（SVA），这是一个动态和空间感知的连接器，它将高分辨率视觉功能与LLM集成，同时减少标志的数量。此外，作者还讨论从公开可用来源获取高质量的可视化指令调优数据，强调数据源平衡和分配比例的重要性。"", ""对华为的启示"": ""在评估MLLM的能力时，现有的大多数基准都不能正确地衡量以视觉为中心的能力，而且这些基准只有很少的样本。而本文作者提出的基准可以有效地重新用于VQA问题，从而能够评估以视觉为中心的MLLM能力。在进行MLLM模型训练时，两阶段训练是有益的，而且更多的适配器数据会进一步改善结果。结合多个视觉编码器（包括SSL模型）可以提高MLLM在各种基准测试中的性能，特别是在以视觉为中心的任务中。""}, {""核心观点"": ""研究分析了大量基准测试，确定它们在多大程度上依赖视觉输入，发现许多基准测试可以在不使用视觉输入的情况下解决。研究者将基准测试分为四类：一般知识、OCR和图表、以视觉为中心、其他。为解决缺乏以视觉为中心的基准测试问题，他们创建了一个专注于2D和3D理解的新基准测试，并研究了不同的训练方法，发现两阶段训练方法在第二阶段解冻骨干网络是有益的。研究还发现语言监督对所有模型都有益，强大的SSL模型在以视觉为中心的任务中可以与语言监督模型竞争，简单连接多个视觉编码器会导致性能饱和。为解决简单连接的局限性，研究者引入了空间视觉聚合器(SVA)模块，使模型能够利用多个编码器的能力而无需插值并具有空间感知能力。研究收集了大量视觉指令调整数据，并实施了各种策略如数据平衡、数据比例调整和预处理，发现数据平衡对有效训练至关重要。""}, {""核心观点"": ""寒武纪-1是一个多模态LLM家族，专注于计算机视觉。它旨在在现实世界场景中更好地接地感官体验，并专注于以视觉为中心的设计选择。实验使用LLM和视觉指令调整来评估来自20个视觉编码器的表示，并在一般QA等任务、数学、Vista基准测试等知识任务、视觉QA等视觉任务以及OCR和图表任务上进行实验。寒武纪1号引入了空间视觉聚合器（SVA），它旨在从各种分辨率特征中学习并将这些知识与LLM集成，同时减少令牌；它被用作来自编码器的每个视觉潜在嵌入的块。还引入了一个新的基准测试，称为CV-Bench，它是以视觉为中心的基准测试。"", ""对华为的启示"": ""与Gemini（谷歌）、GPT4V (OpenAI)、Grok (xAI)相比，寒武纪-1使用更少的令牌，并且在上述所有任务中都有更好的表现。本文提出的新的Benchmark具有通用性，尤其有借鉴意义。""}]",,"[{""name"": ""Alex Martinez"", ""position"": ""Technical Lead"", ""company"": ""Vision Systems""}, {""name"": ""Sophia Kim"", ""position"": ""Senior Research Engineer"", ""company"": ""NVIDIA""}]","[{""name"": ""徐亮"", ""id"": ""30121849""}]"
AI for Climate Change,Case Study,2025-04-14,Exploration of how AI is being used to address climate change challenges.,Sustainability,"[{""核心观点"": ""本文探索最优的从线性模型到Transformer的近似方式。为了探索何为最优，作者提出了多种metric：1. 动态内存能力 2. 静态近似能力 3. 最少参数近似。作者发现，在这三个尺度下，现有的线性模型均不能完成对Transformer的近似。作者提出了一种元线性模型的思路，能在这三个尺度上完成对Transformer的近似，并在多个benchmark下得到最优的效果。"", ""对华为的启示"": ""作者提出的三个尺度，对我司线性模型的探索有指导意义，但meta linear model并不一定是最优，最优架构有待探索。""}, {""核心观点"": ""线性复杂度模型，如线性Transformer (LinFormer)、状态空间模型（SSM）和线性RNN (LinRNN)被提出来取代Transformer结构中传统的softmax注意力。但这些线性模型的优化设计各有优缺点。这个工作构建了一个理论框架来比较现有线性模型，提出了三个条件：（1）动态记忆能力；（2）静态近似能力；（3）最小参数近似。在此基础上，提出了（MetaLinearnotation,MetaLA）作为满足这些条件的解决方案。实验表明，MetaLA比现有的线性模型更有效。"", ""对华为的启示"": ""Transformer的出现对现有NPU架构造成了冲击，而线性架构的不断涌现，计算模式尚未达成统一共识。该论文提出的分析框架具有通用性，对未来NPU计算架构设计具有借鉴意义。""}]",,"[{""name"": ""Thomas Green"", ""position"": ""Sustainability Director"", ""company"": ""ClimateAI""}, {""name"": ""Amara Okafor"", ""position"": ""Environmental Data Scientist"", ""company"": ""Earth Analytics""}]","[{""name"": ""曹颖"", ""id"": ""98593307""}, {""name"": ""胡晓"", ""id"": ""75861422""}, {""name"": ""周婷"", ""id"": ""22923053""}]"
Natural Language Processing,Workshop,2025-04-14,Hands-on session covering current NLP techniques and implementations.,NLP,"[{""核心观点"": ""如何在保持高效性和通用性的同时实现语言模型与人类意图的对齐是一个关键问题，目前主流的RLHF等方法在训练资源需求大、训练过程复杂、难以快速迭代等方面都面临挑战。研究提出了Aligner框架，通过学习偏好数据集中答案的纠正残差（原始答案和纠正后答案之间的差异）来实现模型对齐。通过二阶段训练得到一个小型纠错模型，对上游模型的答案进行纠正而非直接生成答案，且仅需一次训练即可适配多个上游模型。在11个不同的上游模型上，Aligner-7B平均提升了68.9%的帮助性和23.8%的无害性，相比DPO和RLHF，对70B模型的对齐分别节省了11.25倍和22.5倍的训练资源，还能稳定提升已对齐模型的性能。"", ""对华为的启示"": ""提供了一种成本更低、实施更简单的模型对齐新方法以及构建长链CoT的一个新思路。框架的即插即用特性使其易于在实际部署中快速迭代和优化。通过纠错学习提高了对齐过程的可解释性和可控性，有助于构建可信AI系统。""}, {""核心观点"": ""为提高大模型答案准确度并缓解幻觉现象，研究人员提出为模型后缀一个即插即用的调节器模块Aligner，将原始回复、基准真相与问题共同输入该模块对其进行训练。该方法灵活适配不同尺寸的开闭源模型，仅2B尺寸Aligner即可对GPT4回复进行有效修正且效果显著，相较SFT、RLHF、DPO等训练大模型本身的方法有明显精度优势。"", ""对华为的启示"": ""添加即插即用模块可在不触及预训大模型参数的情况下有效修正回复的准确性并缓解幻觉，方法简单且灵活适配多种大模型，对于少量提示工程无法解决的时效性偏见、毒性、敏感问题，可考虑快速训练小尺寸专用调节模块用以修正大模型回复。""}]",,"[{""name"": ""Jerry Wang"", ""position"": ""Sales & Marketing Director"", ""company"": ""Manycore Tech""}, {""name"": ""Neo Zhao"", ""position"": ""Senior Solution Specialist"", ""company"": ""Manycore Tech""}]","[{""name"": ""高文"", ""id"": ""71217347""}]"
AI Governance Frameworks,Roundtable,2025-04-15,Discussion on developing effective governance structures for AI systems.,Policy,"[{""核心观点"": ""研究者通过对30位机器学习数据集策展人的访谈，提出了在数据集策展生命周期中面临的挑战和权衡的全面分类法。研究发现，公平性应贯穿于策展过程的各个阶段，包括需求、设计、实施、评估和维护。此外，研究者强调更广泛的公平性问题如何影响数据策展，并提出了促进公平数据集策展实践的系统性变革建议。研究提出多层次分类法将挑战分为数据集生命周期的特定阶段和更广泛的公平性背景，涵盖需求定义、设计决策、实施细节、评估方法和维护策略等方面。这种分类法有助于识别和理解在策展过程中可能遇到的具体挑战和权衡。"", ""对华为的启示"": ""在数据集设计的整个生命周期，包括需求、设计、实施、评估和维护阶段明确考虑公平性，并制定相应的策略和工具，以确保数据集的公平性和代表性。""}, {""核心观点"": ""SFT和RLHF作为大语言模型微调的主要手段，基于其对数据量和训练时间的要求，在实际的对齐问题中仍然受到一定限制。北京大学提出的Aligner模型在原有的大语言模型基础上叠加新的神经网络层，在偏好数据集上对偏好回答的矫正残差进行学习，从而达到对齐效果。作为大模型微调的另一种新兴技术，视觉重编程（VR）从两方面对模型进行对齐，输入层和输出层。墨尔本大学在现有的一对一VR映射基础上，提出基于概率分布的VR模型，并通过贝叶斯条件分布来计算映射标签矩阵。针对机器学习训练集中的公平性（fairness）问题，斯坦福大学、索尼AI等机构对三十位数据集构造者进行访问，提出了一个关于数据集构造周期中所遇到的挑战的分类学，并将挑战映射为五个阶段：要求阶段、设计阶段、执行阶段、测试阶段和维护阶段。"", ""对华为的启示"": ""在主流的大语言模型微调手段诸如SFT和RLHF之外，VR和其他对齐技术仍然值得重视。除此之外，斯坦福大学和索尼AI提出的数据集构造分类学，对华为研发过程中的训练集构造，存在积极意义。""}]",,"[{""name"": ""Victoria Reynolds"", ""position"": ""Policy Director"", ""company"": ""AI Governance Institute""}, {""name"": ""James Chen"", ""position"": ""Legal Counsel for AI"", ""company"": ""Regulatory Partners""}]","[{""name"": ""曹颖"", ""id"": ""90314948""}, {""name"": ""周婷"", ""id"": ""25240255""}]"
Machine Learning Operations,Technical,2025-04-15,Best practices for deploying and maintaining ML systems at scale.,MLOps,"[{""核心观点"": ""提出了一个解码器-解码器架构YOCO，用于大型语言模型学习。它只缓存一次KV。它由两个组件组成，即堆叠在自解码器之上的交叉解码器。自解码器有效地编码全局key-value (KV)缓存，通过交叉注意力被交叉解码器重用。该设计大幅降低了GPU内存需求，且具有全局注意力的能力。"", ""对华为的启示"": ""Transformer的主要缺陷是内存的需求，在部署时所需KV Cache随着序列长度平方增长。该工作提出了一个YOCO架构，可大幅降低内存需求，对于未来Transformer架构演进或许会有较大意义。对端侧来说，此架构可大幅降低RAM不足的压力。""}, {""核心观点"": ""Transformer架构是LLM的主流框架，但长序列导致的大量KV Kache对GPU memory造成极大的压力，针对该问题清华与微软提出的Decoder-Decoder YOCO架构，该架构只缓存一次KV Cache，512K 长序列下实现9.4x内存节省，Prefilling时延从180s降低到6s；Self-Decoder和Cross-Decoder, Self-Decoder利用self-attention获取全局KV缓存，cross-decoder通过Cross-attention共享这些缓存,从而比标准Transformer节省大量内存占用"", ""对华为的启示"": ""Transformer作为LLM主流架构，已卷入太多的学术界工业界资源，有绝对的技术生态优势，重视Transformer架构基础上的优化创新，充分利用Transformer的技术生态优势。""}]",,"[{""name"": ""Carlos Rodriguez"", ""position"": ""MLOps Team Lead"", ""company"": ""AmazonAWS""}, {""name"": ""Emma Wilson"", ""position"": ""DevOps Engineer"", ""company"": ""MLFlow Systems""}]","[{""name"": ""胡晓"", ""id"": ""52116118""}, {""name"": ""吴强"", ""id"": ""29858791""}, {""name"": ""朱琳"", ""id"": ""21016548""}]"
AI in Financial Services,Industry,2025-04-16,How financial institutions are leveraging AI for fraud detection and risk assessment.,Finance,"[{""核心观点"": ""研究提出了一种名为NeuroSymbolic-CoT（神经符号链式思考）的新型推理框架，将神经网络的表征能力与符号系统的逻辑推理能力相结合。该框架通过三个关键步骤工作：首先将输入问题转化为符号表示形式，然后在符号空间中执行逻辑推理操作，最后将推理结果映射回自然语言回答。实验表明，与传统的纯神经网络方法相比，该方法在数学推理、常识推理和多步逻辑任务上平均提高了23.7%的准确率，同时大幅减少了幻觉现象。"", ""对华为的启示"": ""神经符号融合是突破当前大模型推理瓶颈的重要方向，值得在华为内部大模型研发中重点关注。该方法可以显著提升模型在结构化推理任务中的表现，特别适合应用于需要精确逻辑和可解释性的场景，如金融分析、科学研究和关键决策支持系统。""}]",,"[{""name"": ""Hiroshi Tanaka"", ""position"": ""Head of AI Strategy"", ""company"": ""Global Banking Corp""}, {""name"": ""Priya Sharma"", ""position"": ""FinTech Innovation Lead"", ""company"": ""AI Finance Partners""}]","[{""name"": ""陈晓"", ""id"": ""44779007""}]"
Generative AI Frontiers,Keynote,2025-04-16,Exploring the cutting edge of generative models and creative applications.,Generative AI,"[{""核心观点"": ""研究团队提出了一种新型注意力机制——集成动态注意力网络(EDAN)，通过将多个不同类型的注意力头集成到单一架构中，并根据输入数据的特性动态分配注意力资源。在处理不同模态数据时，EDAN自动识别并激活最适合的注意力模式，显著提升了模型在多模态任务上的表现。实验结果显示，EDAN在视觉-语言跨模态理解基准测试中比传统Transformer架构平均提高了8.2%的性能，同时计算效率提升了35%。"", ""对华为的启示"": ""EDAN架构为华为的多模态AI系统提供了新的设计思路，特别是在计算资源受限的场景中，可大幅提升模型效率和性能。建议在下一代多模态模型中采用类似的动态注意力分配机制，以更好地处理不同类型的输入数据。""}]",,"[{""name"": ""Marcus Lee"", ""position"": ""Chief Research Officer"", ""company"": ""OpenAI""}, {""name"": ""Samantha Wright"", ""position"": ""Creative AI Director"", ""company"": ""Generative Studios""}]","[{""name"": ""杨光"", ""id"": ""71372382""}, {""name"": ""董健"", ""id"": ""46746229""}, {""name"": ""郭平"", ""id"": ""88442919""}]"
Multimodal Learning Systems,Research,2025-04-17,Recent research on systems that combine multiple forms of data input and processing.,Research,"[{""核心观点"": ""研究提出了一种名为Gradient-Guided Data Augmentation (GGDA)的数据增强技术，通过分析模型梯度信息来识别训练数据中的弱点区域，并有针对性地生成高质量的合成样本。GGDA首先构建梯度敏感度图，找出模型学习困难或数据稀缺的区域，然后使用条件生成模型在这些区域创建新的训练样本。实验表明，与传统随机数据增强相比，GGDA可将模型性能提升18.3%，特别是在极端场景和长尾分布上表现突出。"", ""对华为的启示"": ""GGDA技术为华为AI模型训练提供了一种高效的数据增强策略，特别适合解决数据不平衡和稀缺问题。建议在自动驾驶、异常检测等关键业务领域应用此技术，可大幅提升模型在罕见场景下的鲁棒性，同时降低数据采集和标注成本。""}]",,"[{""name"": ""Daniel Park"", ""position"": ""Principal Researcher"", ""company"": ""Multimodal AI Lab""}, {""name"": ""Olivia Chang"", ""position"": ""Research Scientist"", ""company"": ""MIT Media Lab""}]","[{""name"": ""林峰"", ""id"": ""48666201""}]"
AI Accessibility,Workshop,2025-04-17,Creating inclusive AI systems that work for people of all abilities.,Inclusion,,,"[{""name"": ""Rafael Gonzalez"", ""position"": ""Accessibility Specialist"", ""company"": ""Inclusive Technology""}, {""name"": ""Maya Washington"", ""position"": ""User Experience Researcher"", ""company"": ""AccessAI""}]","[{""name"": ""郑洁"", ""id"": ""78113070""}, {""name"": ""冯雪"", ""id"": ""66953606""}]"
